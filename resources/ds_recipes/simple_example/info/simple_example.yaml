---
# Dataset Recipe:
# each recipe is a set of rules to select voices/heads/rooms to be used to 
# render a selection of audio scenes.
syntax:
  name: ds_recipe
  version:
    major: 0
    minor: 1
    revision: 0

#
# recipe
#
name: simple_example

output:
  path: datasets/simple_example
  store_info: True
  audio:
    format:
      type: wav
      subtype: pcm_s16le
      samplerate: 48000

#
# set is a collection of scenes that will be grouped in a subfolder (same name)
#
sets:
  # train/test/validate : only listed sets will be rendered
  
  train:
    # each task is a separate selection
    # of voices/heads/rooms needed to render a scene.
    # if you want to render each scene with default values
    # leave the voices/heads/rooms empty and the one
    # specified in the recipe will be used.
  
    # for voice/heads/rooms specification do not add the ".yaml"
    # use only filename without extention

    tasks:
      # note: if multiple voices are listed they will be used 
      #       according to the scene requirements, matching is done "in sorting order". 
      #       listing more voices than what is required by the scene will not have effects (skipped)

      # TRAIN/TASK #0      
      0:
        # note: this task shows that you can mix&match scenes from different datasets using the right subtype
        #       in this task we use the resources listed in the recipes itself, no customization
        voices:
        heads:
        rooms:
        scenes:
          0:
            subtype: unimore
            info: ["000000_static_singlevoice","000001_static_singlevoice"]
          1:
            subtype: unimore
            info: ["001300_dynamic_multivoice","001301_dynamic_multivoice"]

      # TRAIN/TASK #1
      1:
        # note: this task shows that you can customize (mix&match) heads and rooms for listed scenes
        voices:
        heads:
          0:
            subtype: unimore
            info: ["head_001","head_003"]
          # 1:
          #   subtype: unimore
          #   info: ["head_005","head_004"]
        rooms:
          0:
            subtype: unimore
            info: ["room_brir_001"]
          # 1:
          #   subtype: unimore
          #   info: ["room_brir_002"]
        scenes:
          0:
            subtype: unimore
            info: ["000300_dynamic_singlevoice"]

      # TRAIN/TASK #2
      2:
        # note: this task shows that you can customize (mix&match) voices in a scene
        #       you must list a number of voice that covers the number of voices in the scene
        #       if not .. the scene default will be used.
        #       example: for this "001300_dynamic_multivoice.yaml" there are n.3 voices
        #       in the scene, we customize only the first two. 
        voices:
          0:
            subtype: unimore
            info: ["000001_voice","000003_voice"]
          1:
            subtype: unimore
            info: ["000004_voice"]
        heads:
        rooms:
        scenes:
          0:
            subtype: unimore
            info: ["001300_dynamic_multivoice"]

#       # TRAIN/TASK #3
#       3:
#         # note: this task shows that you can list "all" the scenes in a dataset
#         voices:
#         heads:
#         rooms:
#         scenes:
# #          0:
# #            subtype: librivox_tiny
# #            info: ["!static_one*|mix*"]
# #            info: ["static_one*|mix*"]
# #            info: ["static_onevoice_0000*"]
#           0:
#             subtype: unimore
#             info: ["all"]


  test:


  validate:

#
# script hooks & lib import for data preparation (optional)
#
hooks:
# t.b.d (still needed to define syntax)
# the idea is to allow pre and post processing, like for example 
# to add "analog pink noise" to the rendering and simulate
# analog mic "hissing"
# note: we might need to move this "inside" the task level definition

#EOF
...
